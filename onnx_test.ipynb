{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5439cd5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('batch_size', 16)\n",
      "('device_mem', 0.99)\n",
      "('early_stop', 100)\n",
      "('epochs', 1000)\n",
      "('folderlist', '')\n",
      "('img_folder', '\\\\\\\\10.80.100.13\\\\d\\\\BackendAOI\\\\Data\\\\PassNg_Images\\\\22_XML-282\\\\1_chipping')\n",
      "('img_newsize', 400)\n",
      "('lr', 0.001)\n",
      "('lrf', 0.2)\n",
      "('mode', 'test')\n",
      "('momentum', 0.925)\n",
      "('num_classes', 2)\n",
      "('output_name', 'classifier')\n",
      "('output_root', 'D:\\\\BackendAOI\\\\Python\\\\cnn\\\\save_model\\\\XML-282_chipping')\n",
      "('over_sampling_scale', 2)\n",
      "('over_sampling_thresh', 1000)\n",
      "('test_weight', '')\n",
      "('valid_keep', 0.15)\n",
      "('warmup_bias_lr', 0.1)\n",
      "('warmup_epochs', 3)\n",
      "('warmup_momentum', 0.8)\n",
      "('weight_decay', 0.0004)\n",
      "('weights', '')\n",
      "('workers', 2)\n",
      "\n",
      "[freeze] layer, 0, Conv2d\n",
      "[freeze] layer, 1, BatchNorm2d\n",
      "[freeze] layer, 2, ReLU\n",
      "[freeze] layer, 3, MaxPool2d\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, Sequential, BasicBlock\n",
      "layer, 4, AdaptiveAvgPool2d, BasicBlock\n",
      "layer, 4, Sequential, Linear\n",
      "\n",
      "\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n",
      "pred =  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "from utils.torch_dataset import ImageFolderDatasetWithValid, letterbox, image_to_model_input\n",
    "from utils.torch_device import get_device, gpu_id\n",
    "from utils.general import one_cycle, increment_path, EMA\n",
    "from utils.export import export_onnx\n",
    "from utils.torch_debug import show_image, conv_visualization\n",
    "from utils.loss import label_smoothing\n",
    "\n",
    "from cfg import ConfigData, HypScratch\n",
    "from cnn_model import initialize_resnet50\n",
    "from cnn_model import initialize_resnet34\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "from utils.scan_files import scan_files_subfolder\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def parse_opt(known=False):\n",
    "    c = ConfigData()\n",
    "    hyp = HypScratch()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--mode', type=str, default='test', help='train or find_label_noise')\n",
    "    parser.add_argument('--img-folder', type=str, default=c.img_folder_root)\n",
    "    parser.add_argument('--folderlist', type=str, default=c.folderlist)\n",
    "    parser.add_argument('--test_weight', type=str, default='')\n",
    "    parser.add_argument('--output-root', type=str, default=c.output_root, help='save to output-root/output-name')\n",
    "    parser.add_argument('--output-name', type=str, default=c.output_name, help='save to output-root/output-name')\n",
    "    # parser.add_argument('--cfg', type=str, default=c.pretrained_cfg, help='model.yaml path')\n",
    "    parser.add_argument('--weights', type=str, default=c.pretrained_weights, help='initial weights path')   \n",
    "    parser.add_argument('--valid-keep', type=float, default=c.valid_keep_ratio)\n",
    "    parser.add_argument('--img-newsize', type=int, default=c.img_newsize, help='train, val image size (pixels)')\n",
    "    # parser.add_argument('--device', default=c.device, help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--device-mem', default=c.device_memory_ratio, help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--workers', type=int, default=c.workers, help='maximum number of dataloader workers')\n",
    "    parser.add_argument('--epochs', type=int, default=c.epochs)\n",
    "    parser.add_argument('--early-stop', type=int, default=c.early_stop)\n",
    "    parser.add_argument('--batch-size', type=int, default=c.batch_size)\n",
    "    parser.add_argument('--num-classes', type=int, default=c.num_classes)\n",
    "    parser.add_argument('--over-sampling-thresh', type=int, default=c.over_sampling_thresh)\n",
    "    parser.add_argument('--over-sampling-scale', type=int, default=c.over_sampling_scale)\n",
    "    # parser.add_argument('--use-adam', type=bool, default=c.use_adam, help='use torch.optim.Adam() optimizer')\n",
    "    # parser.add_argument('--use-finetune', type=bool, default=c.use_finetune)\n",
    "    parser.add_argument('--lr', type=float, default=hyp.lr)\n",
    "    parser.add_argument('--lrf', type=float, default=hyp.lrf)\n",
    "    parser.add_argument('--momentum', type=float, default=hyp.momentum)\n",
    "    parser.add_argument('--weight_decay', type=float, default=hyp.weight_decay)\n",
    "    parser.add_argument('--warmup_epochs', type=int, default=hyp.warmup_epochs)\n",
    "    parser.add_argument('--warmup_momentum', type=float, default=hyp.warmup_momentum)\n",
    "    parser.add_argument('--warmup_bias_lr', type=float, default=hyp.warmup_bias_lr)\n",
    "    opt = parser.parse_known_args()[0] if known else parser.parse_args()\n",
    "    for o in opt._get_kwargs():\n",
    "        print(o)\n",
    "    print('')\n",
    "    return opt\n",
    "\n",
    "\n",
    "def save_train_curve(train_loss_history, val_loss_history, val_f1_history, output_folder):\n",
    "    # plot history\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    ax[0].plot(train_loss_history)\n",
    "    ax[1].plot(val_loss_history)\n",
    "    ax[2].plot(val_f1_history)\n",
    "    ax[0].set_title('train_loss_history')\n",
    "    ax[1].set_title('val_loss_history')\n",
    "    ax[2].set_title('val_f1_history')\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.savefig(f'{output_folder}/histroy.png')\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def test(opt):\n",
    "\n",
    "    opt.img_folder = r'D:\\List\\PK3078\\AO2201F\\onnx_test\\P'\n",
    "    opt.weights = r'D:\\List\\PK3078\\AO2201F\\classifier\\best.pt'\n",
    "    model = initialize_resnet34(opt.num_classes, opt.weights)\n",
    "    model = model.to(get_device())\n",
    "    model.eval()\n",
    "\n",
    "    # dataset\n",
    "    img_newsize = opt.img_newsize\n",
    "    img_folder_root = opt.img_folder\n",
    "    files = scan_files_subfolder(img_folder_root, ['jpg','jpeg','bmp','png'])\n",
    "    random.shuffle(files)\n",
    "    # files = files[:200]\n",
    "    # add output report\n",
    "    os.makedirs(opt.img_folder+'\\\\output_report', exist_ok=True)\n",
    "    txt_file = open(opt.img_folder+'\\\\output_report\\\\results.txt','w')\n",
    "    os.makedirs(opt.img_folder+'\\\\output_report\\\\pass_output', exist_ok=True)\n",
    "    #os.makedirs(opt.img_folder+'\\\\output_report\\\\blur_to_normal', exist_ok=True)\n",
    "    os.makedirs(opt.img_folder+'\\\\output_report\\\\fail_output', exist_ok=True)\n",
    "    \n",
    "    print('\\n')\n",
    "    n = len(files)\n",
    "    with torch.no_grad():\n",
    "        for index, file in enumerate(files):\n",
    "            # load\n",
    "            img = cv2.imdecode(np.fromfile(file, dtype=np.uint8), -1)\n",
    "            # img = center_crop(img, (512, 512))\n",
    "            img, ratio, pad = letterbox(img, (img_newsize, img_newsize))\n",
    "            \n",
    "            #inference for onnx\n",
    "            inputs = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "            inputs = np.ascontiguousarray(inputs)\n",
    "            inputs = inputs.astype(np.float32) / 255.0  # uint8 to float32, 0-255 to 0.0-1.0 \n",
    "            inputs = np.expand_dims(inputs, axis=0)\n",
    "\n",
    "            session = onnxruntime.InferenceSession(r'D:\\List\\PK3078\\AO2201F\\classifier\\best.onnx', None)\n",
    "            input_name = session.get_inputs()[0].name\n",
    "            output_name = session.get_outputs()[0].name\n",
    "\n",
    "            result = session.run([output_name], {input_name: inputs})\n",
    "            prediction=int(np.argmax(np.array(result).squeeze(), axis=0))\n",
    "            print('pred = ', prediction)\n",
    "\n",
    "            ## inference for pt\n",
    "            # to tensor\n",
    "#             inputs = image_to_model_input(img, True)\n",
    "#             inputs = inputs.to(get_device())\n",
    "            \n",
    "#             outputs = []\n",
    "#             outputs, conv_outputs = model(inputs)           \n",
    "#             fc = list(model.fc.modules())[1]\n",
    "#             pred = int(torch.argmax(outputs[0]))\n",
    "#             print(f'[{index}/{n}] inference outputs = {outputs}, pred = {pred}, path = {file}') \n",
    "#             # return  \n",
    "#             txt_file.write(\"class pass score = \"+(str(outputs).split(\", \")[0]).split('([[')[1]+\", class fail score = \"+(str(outputs).split(\", \")[1]).split(']]')[0]+\"\\n\")    \n",
    "#             txt_file.write(f'[{index}/{n}] path = {file} , pred = {pred}'+\"\\n\")\n",
    "#             if f'{pred}' == '0':\n",
    "#                 #if float((str(outputs).split(\", \")[0]).split('([[')[1]) > 2.5: \n",
    "#                     pass_img = cv2.imread(f'{file}')\n",
    "#                     cv2.imwrite(opt.img_folder+'/output_report/pass_output/'+(str(outputs).split(\", \")[0]).split('([[')[1]+\"_\"+(str(outputs).split(\", \")[1]).split(']]')[0]+\".jpg\",pass_img)\n",
    "#                 #else:\n",
    "#                     #nornal_img = cv2.imread(f'{file}')\n",
    "#                     #cv2.imwrite(opt.img_folder+'/output_report/blur_to_normal/'+(str(outputs).split(\", \")[0]).split('([[')[1]+\"_\"+(str(outputs).split(\", \")[1]).split(']]')[0]+\".jpg\",nornal_img)\n",
    "#             if f'{pred}' == '1':\n",
    "#                 fail_img = cv2.imread(f'{file}')\n",
    "#                 cv2.imwrite(opt.img_folder+'/output_report/fail_output/'+(str(outputs).split(\", \")[0]).split('([[')[1]+\"_\"+(str(outputs).split(\", \")[1]).split(']]')[0]+\".jpg\",fail_img)\n",
    "\n",
    "def main(opt):\n",
    "    # gpu memory limit\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_device(gpu_id)\n",
    "        torch.cuda.set_per_process_memory_fraction(opt.device_mem, gpu_id)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('torch.cuda.current_device() = ', torch.cuda.current_device())\n",
    "\n",
    "    if opt.mode == 'train':\n",
    "        train(opt)\n",
    "    if opt.mode == 'test':\n",
    "        test(opt)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    opt = parse_opt(True)\n",
    "    main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432cfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd3669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc0a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
